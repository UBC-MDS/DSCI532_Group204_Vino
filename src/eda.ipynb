{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import googlemaps\n",
    "import requests\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_json('../data/winemag-data-130k-v2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTER ROWS BY COUNTRY (Include Only US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"country == 'US'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO PRELIMINARY ANALYSIS ON US DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe columns are:\n",
      "['points',\n",
      " 'title',\n",
      " 'description',\n",
      " 'taster_name',\n",
      " 'taster_twitter_handle',\n",
      " 'price',\n",
      " 'designation',\n",
      " 'variety',\n",
      " 'region_1',\n",
      " 'region_2',\n",
      " 'province',\n",
      " 'country',\n",
      " 'winery']\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataframe columns are:\")\n",
    "pprint(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54,504 total ratings.\n",
      "\n",
      "There are 1 unique countries represented.\n",
      "\n",
      "There are 27 unique provinces represented.\n",
      "\n",
      "There are 265 unique region 1's represented.\n",
      "\n",
      "There are 18 unique region 2's represented.\n",
      "\n",
      "There are 257 unique varieties.\n",
      "\n",
      "There are 5,375 unique wineries.\n",
      "\n",
      "There are 16 tasters.\n",
      "\n",
      "The price ranges from $4 to $2,013 per bottle.\n",
      "\n",
      "The average price is $37 per bottle.\n",
      "\n",
      "The points range from 80 to 100 per bottle.\n",
      "\n",
      "The average point rating is 89 per bottle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {:,.0f} total ratings.\\n\".format(len(df)))\n",
    "print(f\"There are {len(df.country.unique())} unique countries represented.\\n\")\n",
    "print(f\"There are {len(df.province.unique())} unique provinces represented.\\n\")\n",
    "print(f\"There are {len(df.region_1.unique())} unique region 1's represented.\\n\")\n",
    "print(f\"There are {len(df.region_2.unique())} unique region 2's represented.\\n\")\n",
    "print(f\"There are {len(df.variety.unique())} unique varieties.\\n\")\n",
    "print(\"There are {:,.0f} unique wineries.\\n\".format(len(df.winery.unique())))\n",
    "print(f\"There are {len(df.taster_name.unique())} tasters.\\n\")\n",
    "print(\"The price ranges from ${:,.0f} to ${:,.0f} per bottle.\\n\".format(df.price.min(), df.price.max()))\n",
    "print(\"The average price is ${:,.0f} per bottle.\\n\".format(df.price.mean()))\n",
    "print(\"The points range from {:,.0f} to {:,.0f} per bottle.\\n\".format(df.points.min(), df.points.max()))\n",
    "print(\"The average point rating is {:,.0f} per bottle.\\n\".format(df.points.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECIFY GOOGLE MAPS API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='ADD_YOUR_API_KEY_HERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD THE COUNTIES TO EACH ROW USING GOOGLE MAPS API \n",
    "##### Uncomment to run - takes a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wineries = {}\n",
    "# for winery in list(df.winery.unique()):\n",
    "#     geocode_result = gmaps.geocode(winery + ' Winery')\n",
    "#     try:\n",
    "#         for component in geocode_result[0]['address_components']:\n",
    "#             if component['types'][0] == 'administrative_area_level_2':\n",
    "#                 wineries[winery] = component['long_name']\n",
    "#     except:\n",
    "#         print(\"No geolocation for\", winery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE THE COUNTIES DATAFRAME TO DF AND SAVE TO CSV\n",
    "#### This will remove rows without a matched country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineries_df = pd.DataFrame([wineries])\n",
    "wineries_df = wineries_df.melt(var_name = 'winery', value_name = 'county')\n",
    "merged_df = df.merge(wineries_df, on='winery')\n",
    "\n",
    "# Save to csv\n",
    "merged_df.to_csv('../data/us_wineries_with_counties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE MERGED DF FROM CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('../data/us_wineries_with_counties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN THE MISLABELED COLUMNS\n",
    "##### \"America\" and \"Washington-Oregon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df['county'] == 'Yamhill County') & (merged_df['province'] == 'America'), 'province'] = 'Oregon'\n",
    "merged_df.loc[(merged_df['county'] == 'Bernalillo County') & (merged_df['province'] == 'America'), 'province'] = 'New Mexico'\n",
    "merged_df.loc[(merged_df['county'] == 'Buncombe County') & (merged_df['province'] == 'America'), 'province'] = 'North Carolina'\n",
    "merged_df.loc[(merged_df['county'] == 'Steuben County') & (merged_df['province'] == 'America'), 'province'] = 'New York'\n",
    "merged_df.loc[(merged_df['county'] == 'Canyon County') & (merged_df['province'] == 'America'), 'province'] = 'Idaho'\n",
    "merged_df.loc[(merged_df['county'] == 'Santa Barbara County') & (merged_df['province'] == 'America'), 'province'] = 'California'\n",
    "merged_df.loc[(merged_df['county'] == 'Benton County') & (merged_df['province'] == 'America'), 'province'] = 'Washington'\n",
    "merged_df.loc[(merged_df['county'] == 'Yavapai County') & (merged_df['province'] == 'America'), 'province'] = 'Arizona'\n",
    "merged_df.loc[(merged_df['county'] == 'King County') & (merged_df['province'] == 'America'), 'province'] = 'Washington'\n",
    "merged_df.loc[(merged_df['county'] == 'St. Charles County') & (merged_df['province'] == 'America'), 'province'] = 'Missouri'\n",
    "merged_df.loc[(merged_df['county'] == 'Barnstable County') & (merged_df['province'] == 'America'), 'province'] = 'Massachusetts'\n",
    "merged_df.loc[(merged_df['county'] == 'Gem County') & (merged_df['province'] == 'America'), 'province'] = 'Idaho'\n",
    "merged_df.loc[(merged_df['county'] == 'Culpeper County') & (merged_df['province'] == 'America'), 'province'] = 'Virginia'\n",
    "merged_df.loc[(merged_df['county'] == 'Washington County') & (merged_df['province'] == 'America'), 'province'] = 'Oregon'\n",
    "merged_df.loc[(merged_df['county'] == 'Denver County') & (merged_df['province'] == 'America'), 'province'] = 'Colorado'\n",
    "merged_df.loc[(merged_df['county'] == 'Nez Perce County') & (merged_df['province'] == 'America'), 'province'] = 'Idaho'\n",
    "merged_df.loc[(merged_df['county'] == 'Worcester County') & (merged_df['province'] == 'America'), 'province'] = 'Maryland'\n",
    "merged_df.loc[(merged_df['county'] == 'Barrow County') & (merged_df['province'] == 'America'), 'province'] = 'Georgia'\n",
    "merged_df.loc[(merged_df['county'] == 'Sonoma County') & (merged_df['province'] == 'America'), 'province'] = 'California'\n",
    "merged_df.loc[(merged_df['county'] == 'Windham County') & (merged_df['province'] == 'America'), 'province'] = 'Vermont'\n",
    "merged_df.loc[(merged_df['county'] == 'Polk County') & (merged_df['province'] == 'America'), 'province'] = 'Florida'\n",
    "merged_df.loc[(merged_df['county'] == 'Napa County') & (merged_df['province'] == 'America'), 'province'] = 'California'\n",
    "merged_df.loc[(merged_df['county'] == 'Warren County') & (merged_df['province'] == 'America'), 'province'] = 'New York'\n",
    "merged_df.loc[(merged_df['county'] == 'Jackson County') & (merged_df['province'] == 'America'), 'province'] = 'Illinois'\n",
    "merged_df.loc[(merged_df['county'] == 'Monroe County') & (merged_df['province'] == 'America'), 'province'] = 'Indiana'\n",
    "merged_df.loc[(merged_df['county'] == 'Cook County') & (merged_df['province'] == 'Washington-Oregon'), 'province'] = 'Washington'\n",
    "merged_df.loc[(merged_df['county'] == 'Lane County') & (merged_df['province'] == 'Washington-Oregon'), 'province'] = 'Oregon'\n",
    "merged_df.loc[(merged_df['county'] == 'Yamhill County') & (merged_df['province'] == 'Washington-Oregon'), 'province'] = 'Oregon'\n",
    "merged_df.loc[(merged_df['county'] == 'Multnomah County') & (merged_df['province'] == 'Washington-Oregon'), 'province'] = 'Oregon'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET THE US-ATLAS COUNTY AND STATE IDENTIFIERS\n",
    "##### Reference: https://github.com/topojson/us-atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Counties\n",
    "counties_url = 'https://cdn.jsdelivr.net/npm/us-atlas@3/counties-10m.json'\n",
    "counties = requests.get(counties_url)\n",
    "counties_data = counties.json()\n",
    "\n",
    "# Get States\n",
    "states_url = 'https://cdn.jsdelivr.net/npm/us-atlas@3/states-10m.json'\n",
    "states = requests.get(states_url)\n",
    "states_data = states.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP THE COUNTY AND STATE IDS TO THE MERGED DF\n",
    "##### This can take several minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of geometry dictionaries which contain county/state name and ID\n",
    "counties = counties_data['objects']['counties']['geometries']\n",
    "states = states_data['objects']['states']['geometries']\n",
    "\n",
    "def extract_ids(identifier, _type):\n",
    "    \"\"\"\n",
    "    Get a dictionary of the state/county name and corresponding id.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    identifier -- (dict) state or county dictionary with name and id\n",
    "    _type -- (str) either 'county' or 'state' as a string.\n",
    "    \n",
    "    Returns a dictionary of mapped state/county names and ids.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for item in identifier:\n",
    "        # Remove leading '0' for correct mapping later\n",
    "        if item['id'][0] == '0':\n",
    "            item['id'] = item['id'][1:]\n",
    "        if _type == 'county':\n",
    "            if data.get(item['properties']['name'], None):\n",
    "                data[item['properties']['name']].append(item['id'])\n",
    "            else:\n",
    "                data[item['properties']['name']] = [item['id']]\n",
    "        else:\n",
    "            data[item['properties']['name']] = item['id']\n",
    "    return data\n",
    "\n",
    "# Get the states and counties dicts\n",
    "counties_dict = extract_ids(counties, 'county')\n",
    "states_dict = extract_ids(states, 'state')\n",
    "\n",
    "# Add an 'id' columns to the df for state and county\n",
    "merged_df['county_id'] = np.nan\n",
    "merged_df['state_id'] = np.nan\n",
    "\n",
    "# Rename the 'province' column to 'state'\n",
    "merged_df = merged_df.rename(columns={'province': 'state'})\n",
    "\n",
    "# Copy the df to iterate over and add ids\n",
    "merged_copy = merged_df.copy()\n",
    "\n",
    "# Add county id's to merged df row by county name\n",
    "for i, row in merged_copy.iterrows():\n",
    "    county = row['county'].replace(' County', '')\n",
    "    state = row['state']\n",
    "    \n",
    "    # Continue if state or county can't be matched\n",
    "    if counties_dict.get(county, None) is None:\n",
    "        continue\n",
    "    if states_dict.get(state, None) is None:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Match the state_id\n",
    "    merged_df.loc[i, 'state_id'] = states_dict[state]\n",
    "    merged_df.loc[i, 'state'] = state\n",
    "    \n",
    "    \n",
    "    # Match the county_id with the correct state\n",
    "    if len(counties_dict[county]) == 1:\n",
    "        merged_df.loc[i, 'county_id'] = counties_dict[county][0]\n",
    "    else:\n",
    "        for _id in counties_dict[county]:\n",
    "            if _id[:len(states_dict[state])] == states_dict[state]:\n",
    "                merged_df.loc[i, 'county_id'] = _id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN DATA WITH MISSING COUNTY ID's\n",
    "##### Some counties weren't valid and were not in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[pd.notnull(merged_df['county_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE THE FILTERED AND CLEANED DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49,205 total ratings.\n",
      "\n",
      "There are 1 unique countries represented.\n",
      "\n",
      "There are 29 unique states represented.\n",
      "\n",
      "There are 257 unique region 1's represented.\n",
      "\n",
      "There are 18 unique region 2's represented.\n",
      "\n",
      "There are 251 unique varieties.\n",
      "\n",
      "There are 4,204 unique wineries.\n",
      "\n",
      "There are 16 tasters.\n",
      "\n",
      "The price ranges from $4 to $750 per bottle.\n",
      "\n",
      "The average price is $37 per bottle.\n",
      "\n",
      "The points range from 80 to 100 per bottle.\n",
      "\n",
      "The average point rating is 89 per bottle.\n",
      "\n",
      "There are 275 missing values in region_1\n",
      "\n",
      "There are 3,700 missing values in region_2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {:,.0f} total ratings.\\n\".format(len(merged_df)))\n",
    "print(f\"There are {len(merged_df.country.unique())} unique countries represented.\\n\")\n",
    "print(f\"There are {len(merged_df.state.unique())} unique states represented.\\n\")\n",
    "print(f\"There are {len(merged_df.region_1.unique())} unique region 1's represented.\\n\")\n",
    "print(f\"There are {len(merged_df.region_2.unique())} unique region 2's represented.\\n\")\n",
    "print(f\"There are {len(merged_df.variety.unique())} unique varieties.\\n\")\n",
    "print(\"There are {:,.0f} unique wineries.\\n\".format(len(merged_df.winery.unique())))\n",
    "print(f\"There are {len(merged_df.taster_name.unique())} tasters.\\n\")\n",
    "print(\"The price ranges from ${:,.0f} to ${:,.0f} per bottle.\\n\".format(merged_df.price.min(), merged_df.price.max()))\n",
    "print(\"The average price is ${:,.0f} per bottle.\\n\".format(merged_df.price.mean()))\n",
    "print(\"The points range from {:,.0f} to {:,.0f} per bottle.\\n\".format(merged_df.points.min(), merged_df.points.max()))\n",
    "print(\"The average point rating is {:,.0f} per bottle.\\n\".format(merged_df.points.mean()))\n",
    "print(f\"There are {merged_df.region_1.isna().sum()} missing values in region_1\\n\")\n",
    "print(\"There are {:,.0f} missing values in region_2\\n\".format(merged_df.region_2.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD A VALUE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['value'] = merged_df['points'] / merged_df['price']\n",
    "merged_df = merged_df.assign(value_scaled=lambda x: (100 - x.price * 0.1) * x.points/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE THE FINAL CLEANED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop bad index col before saving\n",
    "merged_df = merged_df.iloc[:,1:]\n",
    "merged_df.to_csv('../data/cleaned_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
